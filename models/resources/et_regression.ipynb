{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, RANSACRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "plt.rcParams.update({'figure.figsize':(12,6), 'figure.dpi':100})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "energy_meters_df = pd.read_excel('data/VIS Målere.xlsx')\n",
    "# Remove leading and trailing whitespace in cells with value of type string\n",
    "energy_meters_df = energy_meters_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# parse_dates=['Unnamed: 0']\n",
    "\n",
    "raw_esave_tables_dict = pd.read_excel('data/EsaveExport_Trondheim Kommune_Trondheim_10121314.xls', decimal=',', sheet_name=None)\n",
    "raw_esave_tables_list = raw_esave_tables_dict.values()\n",
    "for table in raw_esave_tables_list:\n",
    "    table.rename(columns={'Unnamed: 0': 'datetime'}, inplace=True)\n",
    "    table['datetime'] = pd.to_datetime(table['datetime'], dayfirst=True)\n",
    "    table.set_index('datetime', inplace=True)\n",
    "    table.sort_index()\n",
    "raw_esave_table = pd.concat(raw_esave_tables_list, axis=1, ignore_index=False)\n",
    "\n",
    "stop_time = time()\n",
    "elapsed_time = stop_time - start_time\n",
    "print(f'Used {elapsed_time:.2f} seconds to read xls files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "buildings = {}\n",
    "current_building = None\n",
    "sensor_types = ['Fastkraft', 'Fjernvarme', 'Varme', 'Elkjel', 'Kjøling']\n",
    "for _, row in energy_meters_df.iterrows():\n",
    "    # if current row is a building not a sensor create a new dict to store all sensors for that building\n",
    "    if row['Objekt'] == 'Bygg':\n",
    "        current_building = {}\n",
    "        for sensor_type in sensor_types:\n",
    "            current_building[sensor_type] = {}\n",
    "        buildings[row['Navn']] = current_building\n",
    "        continue\n",
    "    \n",
    "    sensor_type = row['Type']\n",
    "    if sensor_type in sensor_types:\n",
    "        name = row['Navn']\n",
    "        sensor_id = row['Formel']\n",
    "        current_building[sensor_type][name] = sensor_id\n",
    "\n",
    "\n",
    "stop_time = time()\n",
    "elapsed_time = stop_time - start_time\n",
    "print(f'Used {elapsed_time:.2f} seconds to parse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that contains a dataframe for each building that have column for each sensor type (e.g. Fjernvarme or Fastkraft)\n",
    "building_dfs = {}\n",
    "for building_name, sensor_type_dict in buildings.items():\n",
    "\n",
    "    sensor_type_series = {}\n",
    "    for sensor_type, sensor_dict in sensor_type_dict.items():\n",
    "        for sensor_id in sensor_dict.values():\n",
    "            if sensor_id in raw_esave_table.columns:\n",
    "                sensor_series = raw_esave_table[sensor_id]\n",
    "                if not sensor_type in sensor_type_series:\n",
    "                    sensor_type_series[sensor_type] = sensor_series\n",
    "                else:\n",
    "                    sensor_type_series[sensor_type] = sensor_type_series[sensor_type] + sensor_series\n",
    "    if sensor_type_series:\n",
    "        df = pd.DataFrame(sensor_type_series)\n",
    "        df.sort_index(inplace=True)\n",
    "        df.dropna(axis='index')\n",
    "        building_dfs[building_name] = df\n",
    "\n",
    "# Create a column in each building dataframe that is the total energy consumption, i.e. the sum of all other columns.\n",
    "for building_df in building_dfs.values():\n",
    "    building_df['Totalt'] = building_df[list(building_df.columns)].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data frames for each building that have values for each day or week instead of hourly\n",
    "building_daily_dfs = {}\n",
    "building_weekly_dfs = {}\n",
    "for building_name, building_df in building_dfs.items():\n",
    "    building_daily_dfs[building_name] = building_df.resample('D').sum()\n",
    "    building_weekly_dfs[building_name] = building_df.resample('W-MON').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for building_name, weekly_consumption_dict in building_weekly_dfs.items():\n",
    "    if weekly_consumption_dict['Totalt'].isnull().values.any():\n",
    "        print(f'{building_name} have null values')\n",
    "\n",
    "    if weekly_consumption_dict['Totalt'].isna().values.any():\n",
    "        print(f'{building_name} have nan values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_voll = raw_esave_table['Eklima_68860_TAM']\n",
    "temp_voll_weekly_mean = temp_voll.resample('W-MON').mean()\n",
    "temp_voll_daily_mean = temp_voll.resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_et_curve1(energy_consumption_series: pd.Series, temperature_series: pd.Series):\n",
    "    # print(energy_consumption_series)\n",
    "    # print(temperature_series)\n",
    "    # energy_consumption_series = energy_consumption_series[energy_consumption_series.isin(temperature_series)]\n",
    "    # temperature_series = temperature_series[temperature_series.isin(energy_consumption_series)]\n",
    "\n",
    "    # ensure that we match values for energy and temp, and that there are no nan values.\n",
    "    energy_consumption_series.rename('energy', inplace=True)\n",
    "    temperature_series.rename('temperature', inplace=True)\n",
    "    df = pd.concat((energy_consumption_series, temperature_series), axis=1, ignore_index=False)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.sort_values(by='temperature', inplace=True)\n",
    "\n",
    "    X = df['temperature'].values.reshape(df.shape[0], 1)\n",
    "    y = df['energy'].values.reshape(df.shape[0], 1)\n",
    "\n",
    "    # linear regression\n",
    "    # model = LinearRegression()\n",
    "    # model.fit(X, y)\n",
    "\n",
    "    # plt.scatter(X, y,  color='black')\n",
    "    # plt.plot(X, model.predict(X), color='blue', linewidth=3)\n",
    "    # plt.show()\n",
    "\n",
    "    # logistic regression\n",
    "    # model_log = LogisticRegression()\n",
    "    # model_log.fit(X, y)\n",
    "    # plt.scatter(X, y,  color='black')\n",
    "    # plt.plot(X, model_log.predict(X), color='blue', linewidth=3)\n",
    "    # plt.show()\n",
    "\n",
    "    model = SVR(kernel='rbf', C=5000)\n",
    "    # model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    plt.scatter(X, y,  color='black')\n",
    "    plt.plot(X, model.predict(X), color='blue', linewidth=3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(x, x0, y0, x1, y1):\n",
    "    slope = (y1 - y0) / (x1 - x0)\n",
    "    return y0 + (x - x0) * slope\n",
    "\n",
    "class et_curve():\n",
    "    def __init__(self, dx, dy):\n",
    "        self.dx = dx\n",
    "        self.dy = dy\n",
    "\n",
    "    def expected(self, temperature):\n",
    "        if temperature < self.dx[0]:\n",
    "            # print(f'{temperature} is below range, lowest point is ({self.dx[0]}, {self.dy[0]})')\n",
    "            # TODO improve this prediction\n",
    "            return linear_interpolation(temperature, self.dx[0], self.dy[0], self.dx[1], self.dy[1])\n",
    "        if temperature > self.dx[-1]:\n",
    "            # print(f'{temperature} is above range, highest point is ({self.dx[-1]}, {self.dy[-1]})')\n",
    "            return self.dy[-1]\n",
    "\n",
    "        for i in range(len(self.dx) - 1):\n",
    "            if self.dx[i] <= temperature and temperature <= self.dx[i+1]:\n",
    "                return linear_interpolation(temperature, self.dx[i], self.dy[i], self.dx[i+1], self.dy[i+1])\n",
    "    \n",
    "    def get_expected_series(self, temperature_series):\n",
    "        return temperature_series.apply(self.expected)\n",
    "    \n",
    "    def get_proportial_series(self, energy_series, temperature_series):\n",
    "        expected_series = self.get_expected_series(temperature_series)\n",
    "        return energy_series / expected_series\n",
    "\n",
    "    def get_anomolies_series(self, energy_series, temperature_series, threshold):\n",
    "        expected_series = self.get_expected_series(temperature_series)\n",
    "        mask = energy_series / expected_series >= (threshold + 1)\n",
    "        return energy_series[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_et_curve2(energy_consumption_series: pd.Series, temperature_series: pd.Series, points_per_segment, plot: bool = False):\n",
    "\n",
    "    # ensure that we match values for energy and temp, and that there are no nan values.\n",
    "    energy_consumption_series.rename('energy', inplace=True)\n",
    "    temperature_series.rename('temperature', inplace=True)\n",
    "    df = pd.concat((energy_consumption_series, temperature_series), axis=1, ignore_index=False)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.sort_values(by='temperature', inplace=True)\n",
    "\n",
    "    number_of_points = df.shape[0]\n",
    "\n",
    "    X = df['temperature'].values.reshape(number_of_points, 1)\n",
    "    y = df['energy'].values.reshape(number_of_points, 1)\n",
    "\n",
    "    dx = []\n",
    "    dy = []\n",
    "\n",
    "    for i in range(0, number_of_points + 1, points_per_segment):\n",
    "        n = min(points_per_segment, number_of_points - i)\n",
    "\n",
    "        X_seg = X[i:i+n, :]\n",
    "        y_seg = y[i:i+n, :]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_seg, y_seg)\n",
    "\n",
    "        if i == 0:\n",
    "            X_first = X_seg[0].reshape(1,1)\n",
    "            y_first = model.predict(X_first)\n",
    "            dx.append(X_first[0,0])\n",
    "            dy.append(y_first[0,0])\n",
    "\n",
    "        X_middle = X_seg[n//2].reshape(1,1)\n",
    "        y_middle = model.predict(X_middle)\n",
    "        dx.append(X_middle[0,0])\n",
    "        dy.append(y_middle[0,0])\n",
    "\n",
    "        if i >= number_of_points - points_per_segment:\n",
    "            X_last = X_seg[-1].reshape(1,1)\n",
    "            y_last = model.predict(X_last)\n",
    "            dx.append(X_last[0,0])\n",
    "            dy.append(y_last[0,0])\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(dx, dy, color='red', linewidth=3)\n",
    "        plt.scatter(X, y)\n",
    "        plt.show()\n",
    "\n",
    "    return et_curve(dx, dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_et_curve3(energy_consumption_series: pd.Series, temperature_series: pd.Series, points_per_segment, plot: bool = False):\n",
    "\n",
    "    # ensure that we match values for energy and temp, and that there are no nan values.\n",
    "    energy_consumption_series.rename('energy', inplace=True)\n",
    "    temperature_series.rename('temperature', inplace=True)\n",
    "    df = pd.concat((energy_consumption_series, temperature_series), axis=1, ignore_index=False)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.sort_values(by='temperature', inplace=True)\n",
    "\n",
    "    number_of_points = df.shape[0]\n",
    "\n",
    "    X = df['temperature'].values.reshape(number_of_points, 1)\n",
    "    y = df['energy'].values.reshape(number_of_points, 1)\n",
    "\n",
    "    dx = []\n",
    "    dy = []\n",
    "\n",
    "    for i in range(0, number_of_points + 1, points_per_segment):\n",
    "        n = min(points_per_segment, number_of_points - i)\n",
    "\n",
    "        X_seg = X[i:i+n, :]\n",
    "        y_seg = y[i:i+n, :]\n",
    "\n",
    "        model = RANSACRegressor()\n",
    "        try:\n",
    "            model.fit(X_seg, y_seg)\n",
    "        except:\n",
    "            # TODO: if we end up using RANSACRegressor we must add some error handling that uses more points for segment if it fails to fit for number of points initially given\n",
    "            continue\n",
    "\n",
    "        if i == 0:\n",
    "            X_first = X_seg[0].reshape(1,1)\n",
    "            y_first = model.predict(X_first)\n",
    "            dx.append(X_first[0,0])\n",
    "            dy.append(y_first[0,0])\n",
    "\n",
    "        X_middle = X_seg[n//2].reshape(1,1)\n",
    "        y_middle = model.predict(X_middle)\n",
    "        dx.append(X_middle[0,0])\n",
    "        dy.append(y_middle[0,0])\n",
    "\n",
    "        if i >= number_of_points - points_per_segment:\n",
    "            X_last = X_seg[-1].reshape(1,1)\n",
    "            y_last = model.predict(X_last)\n",
    "            dx.append(X_last[0,0])\n",
    "            dy.append(y_last[0,0])\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(dx, dy, color='red', linewidth=3)\n",
    "        plt.scatter(X, y)\n",
    "        plt.show()\n",
    "\n",
    "    return et_curve(dx, dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_building_name = 'Trondheim Kommune - Lilleby skole'\n",
    "\n",
    "et_reg = generate_et_curve3(building_weekly_dfs[test_building_name]['Totalt'], temp_voll_weekly_mean, 40)\n",
    "\n",
    "et_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "et_curves_dict = {}\n",
    "for name, weekly_consumption in building_weekly_dfs.items():\n",
    "    i += 1\n",
    "\n",
    "    num_to_plot = 4\n",
    "    if i < num_to_plot:\n",
    "        print(name)\n",
    "\n",
    "    building_et_curve1 = generate_et_curve2(weekly_consumption['Totalt'], temp_voll_weekly_mean, 50, i < num_to_plot)\n",
    "    building_et_curve2 = generate_et_curve3(weekly_consumption['Totalt'], temp_voll_weekly_mean, 50, i < num_to_plot)\n",
    "    et_curves_dict[building_name] = building_et_curve1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_day_of_week_dfs = {}\n",
    "for building_name in building_dfs.keys():\n",
    "    day_of_week_dict = {}\n",
    "    building_day_of_week_dfs[building_name] = day_of_week_dict\n",
    "    for i in range(7):\n",
    "        day_of_week_dict[i] = building_daily_dfs[building_name].iloc[building_daily_dfs[building_name].index.dayofweek == i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "\n",
    "i = 0\n",
    "et_curves_building_day_of_week = {}\n",
    "for name, day_of_week_dfs in building_day_of_week_dfs.items():\n",
    "\n",
    "    i += 1\n",
    "    num_to_plot = 4\n",
    "    if i < num_to_plot:\n",
    "        print(name)\n",
    "\n",
    "    et_curves_building_day_of_week[name] = {}\n",
    "\n",
    "    for day_of_week, consumption_df in day_of_week_dfs.items():\n",
    "        if i < num_to_plot:\n",
    "            print(week_days[day_of_week])\n",
    "        building_et_curve1 = generate_et_curve2(consumption_df['Totalt'], temp_voll_daily_mean, 50, i < num_to_plot)\n",
    "        # building_et_curve2 = generate_et_curve3(consumption_df['Totalt'], temp_voll_daily_mean, 50, i < num_to_plot)\n",
    "        et_curves_building_day_of_week[name][day_of_week] = building_et_curve1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ac82abe5bd5dc64103c193a10ddf3874892ec2efe60c6d5640b2e3c05faa57e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
