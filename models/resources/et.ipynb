{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "plt.rcParams.update({'figure.figsize':(12,6), 'figure.dpi':100})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "energy_meters_df = pd.read_excel('data/VIS Målere.xlsx')\n",
    "# Remove leading and trailing whitespace in cells with value of type string\n",
    "energy_meters_df = energy_meters_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# parse_dates=['Unnamed: 0']\n",
    "\n",
    "raw_esave_tables_dict = pd.read_excel('data/EsaveExport_Trondheim Kommune_Trondheim_10121314.xls', decimal=',', sheet_name=None)\n",
    "raw_esave_tables_list = raw_esave_tables_dict.values()\n",
    "for table in raw_esave_tables_list:\n",
    "    table.rename(columns={'Unnamed: 0': 'datetime'}, inplace=True)\n",
    "    table['datetime'] = pd.to_datetime(table['datetime'], dayfirst=True)\n",
    "    table.set_index('datetime', inplace=True)\n",
    "    table.sort_index()\n",
    "raw_esave_table = pd.concat(raw_esave_tables_list, axis=1, ignore_index=False)\n",
    "\n",
    "stop_time = time()\n",
    "elapsed_time = stop_time - start_time\n",
    "print(f'Used {elapsed_time:.2f} seconds to read xls files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "\n",
    "buildings = {}\n",
    "current_building = None\n",
    "sensor_types = ['Fastkraft', 'Fjernvarme', 'Varme', 'Elkjel', 'Kjøling']\n",
    "for _, row in energy_meters_df.iterrows():\n",
    "    # if current row is a building not a sensor create a new dict to store all sensors for that building\n",
    "    if row['Objekt'] == 'Bygg':\n",
    "        current_building = {}\n",
    "        for sensor_type in sensor_types:\n",
    "            current_building[sensor_type] = {}\n",
    "        buildings[row['Navn']] = current_building\n",
    "        continue\n",
    "    \n",
    "    sensor_type = row['Type']\n",
    "    if sensor_type in sensor_types:\n",
    "        name = row['Navn']\n",
    "        sensor_id = row['Formel']\n",
    "        current_building[sensor_type][name] = sensor_id\n",
    "\n",
    "\n",
    "stop_time = time()\n",
    "elapsed_time = stop_time - start_time\n",
    "print(f'Used {elapsed_time:.2f} seconds to parse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that contains a dataframe for each building that have column for each sensor type (e.g. Fjernvarme or Fastkraft)\n",
    "building_dfs = {}\n",
    "for building_name, sensor_type_dict in buildings.items():\n",
    "\n",
    "    sensor_type_series = {}\n",
    "    for sensor_type, sensor_dict in sensor_type_dict.items():\n",
    "        for sensor_id in sensor_dict.values():\n",
    "            if sensor_id in raw_esave_table.columns:\n",
    "                sensor_series = raw_esave_table[sensor_id]\n",
    "                if not sensor_type in sensor_type_series:\n",
    "                    sensor_type_series[sensor_type] = sensor_series\n",
    "                else:\n",
    "                    sensor_type_series[sensor_type] = sensor_type_series[sensor_type] + sensor_series\n",
    "    if sensor_type_series:\n",
    "        building_dfs[building_name] = pd.DataFrame(sensor_type_series)\n",
    "        building_dfs[building_name].sort_index()\n",
    "\n",
    "# Create a column in each building dataframe that is the total energy consumption, i.e. the sum of all other columns.\n",
    "for building_df in building_dfs.values():\n",
    "    building_df['Totalt'] = building_df[list(building_df.columns)].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new data frames for each building that have values for each day or week instead of hourly\n",
    "building_daily_dfs = {}\n",
    "building_weekly_dfs = {}\n",
    "for building_name, building_df in building_dfs.items():\n",
    "    building_daily_dfs[building_name] = building_df.resample('D').sum()\n",
    "    building_weekly_dfs[building_name] = building_df.resample('W-MON').sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_temperature_df = pd.read_excel('data/ET Kurver.xlsx')\n",
    "# Remove leading and trailing whitespace in column names\n",
    "energy_temperature_df.columns = energy_temperature_df.columns.str.strip()\n",
    "# Remove leading and trailing whitespace in cells with value of type string\n",
    "energy_temperature_df = energy_temperature_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "# energy_temperature_df.set_index('Bygg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(x, x0, y0, x1, y1):\n",
    "    slope = (y1 - y0) / (x1 - x0)\n",
    "    return y0 + (x - x0) * slope\n",
    "\n",
    "class et_curve():\n",
    "    def __init__(self, baseline, dx, dy):\n",
    "        self.baseline = baseline\n",
    "        self.dx = dx\n",
    "        self.dy = dy\n",
    "\n",
    "    def expected(self, temperature):\n",
    "        if temperature < self.dx[0]:\n",
    "            print(f'{temperature} is below range, lowest point is ({self.dx[0]}, {self.dy[0]})')\n",
    "            # TODO improve this prediction\n",
    "            return linear_interpolation(temperature, self.dx[0], self.dy[0], self.dx[1], self.dy[1])\n",
    "        if temperature > self.dx[-1]:\n",
    "            print(f'{temperature} is above range, highest point is ({self.dx[-1]}, {self.dy[-1]})')\n",
    "            return self.dy[-1]\n",
    "\n",
    "        for i in range(len(self.dx) - 1):\n",
    "            if self.dx[i] <= temperature and temperature <= self.dx[i+1]:\n",
    "                return linear_interpolation(temperature, self.dx[i], self.dy[i], self.dx[i+1], self.dy[i+1])\n",
    "    \n",
    "    def get_expected_series(self, temperature_series):\n",
    "        return temperature_series.apply(self.expected)\n",
    "    \n",
    "    def get_proportial_series(self, energy_series, temperature_series):\n",
    "        expected_series = self.get_expected_series(temperature_series)\n",
    "        return energy_series / expected_series\n",
    "\n",
    "    def get_anomolies_series(self, energy_series, temperature_series, threshold):\n",
    "        expected_series = self.get_expected_series(temperature_series)\n",
    "        mask = energy_series / expected_series >= (threshold + 1)\n",
    "        return energy_series[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def et_curve_from_pandas_row(row: pd.core.series.Series) -> et_curve:\n",
    "    baseline = row['Grunnlast']\n",
    "\n",
    "    dx = []\n",
    "    dy = []\n",
    "    for i in range(1,7):\n",
    "        x = row[f'DX{i}']\n",
    "        y = row[f'DY{i}']\n",
    "        if (not np.isnan(x)) and (not np.isnan(y)):\n",
    "            dx.append(x)\n",
    "            dy.append(y)\n",
    "\n",
    "    return et_curve(baseline, dx, dy)\n",
    "\n",
    "def get_latest_et_curve_from_dict(et_curve_dict):\n",
    "    key = max(et_curve_dict.keys())\n",
    "    return et_curve_dict[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_curves_dict = {}\n",
    "for _, row in energy_temperature_df.iterrows():\n",
    "    building_name = row['Bygg']\n",
    "\n",
    "    valid_from_str = row['Fra']\n",
    "    valid_from = datetime.strptime(valid_from_str, '%d.%m.%Y')\n",
    "\n",
    "    building_et_curve = et_curve_from_pandas_row(row)\n",
    "\n",
    "    if not building_name in et_curves_dict:\n",
    "        et_curves_dict[building_name] = {}\n",
    "    \n",
    "    et_curves_dict[building_name][valid_from] = building_et_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_building_name = 'Trondheim Kommune - Lilleby skole'\n",
    "\n",
    "test_et = None\n",
    "newest_date = datetime(1971, 1, 1)\n",
    "for date, et in et_curves_dict[test_building_name].items():\n",
    "    if date > newest_date:\n",
    "        test_et = et\n",
    "\n",
    "for x, y in zip(test_et.dx, test_et.dy):\n",
    "    plt.plot(x, y, 'rx', markersize=16)\n",
    "\n",
    "for x in range(-30, 30):\n",
    "    prediction = test_et.expected(x)\n",
    "    # print(f'temp: {x} expected: {prediction:.1f} kWh/uke')\n",
    "    plt.plot(x, prediction, 'go')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_voll = raw_esave_table['Eklima_68860_TAM']\n",
    "temp_voll.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_voll_weekly_mean = temp_voll.resample('W-MON').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_prediction_weekly = temp_voll_weekly_mean.apply(test_et.expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_plot = datetime(2018, 1, 1)\n",
    "stop_plot = datetime(2019, 1, 1)\n",
    "\n",
    "consumption_subplot = building_weekly_dfs[test_building_name]['Totalt'].plot(xlim=(start_plot, stop_plot))\n",
    "prediction_subplot = et_prediction_weekly.plot(xlim=(start_plot, stop_plot))\n",
    "plt.legend(['Actual consumption', 'ET prediction'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_consumption_difference_weekly_et = building_weekly_dfs[test_building_name]['Totalt'] - et_prediction_weekly\n",
    "energy_consumption_difference_proportional_weekly_et = energy_consumption_difference_weekly_et / et_prediction_weekly\n",
    "energy_consumption_difference_precent_weekly_et = energy_consumption_difference_proportional_weekly_et * 100\n",
    "\n",
    "energy_consumption_difference_precent_weekly_et.plot(xlim=(start_plot, stop_plot))\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomolies_series = test_et.get_anomolies_series(building_weekly_dfs[test_building_name]['Totalt'], temp_voll_weekly_mean, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomolies_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_weekly_dfs[test_building_name]['Totalt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_weekly_dfs[test_building_name]['Totalt'].plot(xlim=(start_plot, stop_plot))\n",
    "et_prediction_weekly.plot(xlim=(start_plot, stop_plot))\n",
    "plt.legend(['Actual consumption', 'ET prediction'])\n",
    "\n",
    "plt.legend\n",
    "anomolies_series.plot(style=\"rx\", xlim=(start_plot, stop_plot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_prediction_function(proportian_value):\n",
    "    min_v = 1.10\n",
    "    max_v = 1.30\n",
    "    return max(min((proportian_value - min_v) / (max_v - min_v), 1), 0)\n",
    "\n",
    "\n",
    "anomaly_prediction_dict = {}\n",
    "for building_name, et_dict in et_curves_dict.items():\n",
    "    if building_name not in building_weekly_dfs:\n",
    "        print(f'{building_name} not in building_weekly dfs')\n",
    "        continue\n",
    "\n",
    "    energy_consumption_series = building_weekly_dfs[building_name]['Totalt']\n",
    "    \n",
    "    latest_et: et_curve = get_latest_et_curve_from_dict(et_dict)\n",
    "    consumption_prediction_proportion = latest_et.get_proportial_series(energy_consumption_series, temp_voll_weekly_mean)\n",
    "    anomaly_series = consumption_prediction_proportion.apply(anomaly_prediction_function)\n",
    "\n",
    "    anomaly_prediction_dict[building_name] = anomaly_series\n",
    "\n",
    "anomaly_prediction_df = pd.DataFrame(anomaly_prediction_dict)\n",
    "anomaly_prediction_df[test_building_name].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\n",
    "    'data/et_curve_anomaly_confidence.xlsx',\n",
    "    \n",
    ") as writer:\n",
    "    anomaly_prediction_df.to_excel(writer, float_format='%.2f')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ac82abe5bd5dc64103c193a10ddf3874892ec2efe60c6d5640b2e3c05faa57e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
